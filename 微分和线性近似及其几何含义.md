# 微分用于线性近似即其几何含义

## 1 一元微分

### 1.1 导数的定义

设 $f(x)$ 是一个定义在某开区间上的实值函数，且在点 $x_0$ 处可导。其导数 $f'(x_0)$ 定义为极限形式：

$$
f'(x_0) = \lim_{h \to 0} \frac{f(x_0 + h) - f(x_0)}{h}:=\frac{dy}{dx}
$$

此定义描述了函数在 $x_0$ 处的局部变化率

### 1.2 函数局部的行为表征(函数的变化量)

因此在充分小的增量 $h$ 下，函数 $f(x)$ 在 $x_0$ 处的增量可表示为： $dy = f'(x_0) \cdot dx$ 
在局部范围内(同时根据导数的极限定义反推)

$$
\Delta y = f'(x_0) h + o(h)
$$

$$
\Delta y = \underbrace{f'(x_0) \cdot \Delta x}_{\text{线性主部}} + \underbrace{o(\Delta x)}_{\text{高阶无穷小项}}
$$

当局部范围认为足够小时候，我们忽略高阶项，得到函数局部范围的线性近似:

$$
\Delta y \approx f'(x_0) \Delta x
$$

等价的表述为:

$$
f(x) - f(x_0) = f'(x_0) (x - x_0)
$$

$$
f(x + h) - f(x) = f'(x) h
$$

该线性近似可以用于"线性"的表征这个函数的局部行为，而**全域满足该线性近似**的显然是该点的切线方程，即**局部线性近似的全域延拓即为切线方程本身**

故切线方程为:

$$
f(x) = f'(x_0) (x - x_0) + f(x_0)
$$

其中 $x$ 在合理局部范围内是函数的近似表征。

### 1.3 微分的定义

函数在 $x_0$ 处的**微分** $dy$ 定义为线性主部：

$$
dy = f'(x_0) \cdot \Delta x
$$

结合前述增量表达式，我们有：

$$
\Delta y = dy + o(\Delta x) = f'(x_0) \cdot \Delta x + o(\Delta x)
$$

微分 $dy$ 表示函数在 $x_0$ 处沿切线方向的线性增量，而 $o(\Delta x)$ 则代表非线性部分的误差。

### 1.4 线性近似和切线方程

我们通过微来描述函数的局部行为，即
从几何角度，微分对应于函数在 $x_0$ 处的切线上的增量。函数在 $x_0$ 处的切线方程为：

$$
y - f(x_0) = f'(x_0) (x - x_0)
$$

基于此切线方程，我们可以得到函数 $f(x)$ 在 $x_0$ 附近的线性近似：

$$
f(x) \approx f(x_0) + f'(x_0) (x - x_0)
$$

若令 $x = x_0 + h$ （即 $h = x - x_0$ ），则等价形式为：

$$
f(x_0 + h) \approx f(x_0) + f'(x_0) h
$$

然而，这种线性近似仅在 $h$ 充分小时有效，且精度有限，因为它忽略了 $o(\Delta x)$ 中的高阶项。

为了更精确地描述函数在 $x_0$ 附近的局部行为，需要引入高阶导数进行修正。这自然引出了泰勒公式，通过高阶项对函数进行多项式近似，后续分析将进一步展开。

### 1.5 Taylor 公式引入

在线性近似中，我们利用函数在一点的导数（即一阶信息）来估计函数在该点附近的取值。然而，为了更精确地刻画函数的局部行为，我们可以进一步引入函数的高阶导数，构造出**更高阶的近似表达式**。

设函数 $f(x)$ 在某开区间内具有 $n$ 阶连续导数，记 $h = x - x_0$ ，则 $f(x)$ 在点 $x_0$ 附近可展开为：

$$
f(x) = f(x_0) + f'(x_0)h + \frac{f''(x_0)}{2!}h^2 + \cdots + \frac{f^{(n)}(x_0)}{n!}h^n + R_n(h)
$$

其中 $R_n(h)$ 为**余项**，表示高阶近似的误差项，具体形式依赖于所采用的余项形式（如拉格朗日型、皮亚诺型、积分型等）。 
最常见的为**拉格朗日余项**，其形式为：

$$
R_n(h) = \frac{f^{(n+1)}(\xi)}{(n+1)!}h^{n+1}, \quad \text{其中} \ \xi \in (x_0, x)
$$

当 $h \to 0$ 时， $R_n(h) \to 0$ ，因此前 $n$ 项构成函数在 $x_0$ 附近的高阶近似，称为**泰勒多项式（Taylor polynomial）**：

$$
T_n(x) = \sum_{k=0}^{n} \frac{f^{(k)}(x_0)}{k!}(x - x_0)^k
$$

特别地， $n = 1$ 时，Taylor 多项式即为线性近似：

$$
f(x) \approx f(x_0) + f'(x_0)(x - x_0)
$$

这正是前面微分所提供的**一阶逼近**。因此，可以将微分视为 Taylor 展开在一阶截断时所保留的主导部分。

这也恰好是 Lagrange 中值定理的形式:

$$
f(b) - f(a) = f'(\xi)(b - a)
$$

因此这类思想都是用线性量(或更精确一步的使用多项式)去描述函数的局部行为。

## 2 多元函数

### 2.1 偏导数与全微分

#### **偏导数**

对于多元函数 $f: \mathbb{R}^n \to \mathbb{R}$ ，设点 $\mathbf{x}_0 = (x_{01}, x_{02}, \dots, x_{0n})$ 。函数关于第 $i$ 个变量的偏导数定义为：

$$
\frac{\partial f}{\partial x_i}(\mathbf{x}_0) = \lim_{h \to 0} \frac{f(x_{01}, \dots, x_{0i} + h, \dots, x_{0n}) - f(\mathbf{x}_0)}{h}
$$

偏导数表示函数沿 $x_i$ 轴方向的变化率。

**显然，每一个维度增量的叠加即整体增量，即全微分是所有维度的偏微分求和**

#### **全微分**

若 $f$ 在 $\mathbf{x}\_0$ 处对所有变量均可偏导，则当自变量增量 $\Delta \mathbf{x} = (\Delta x_1, \dots, \Delta x_n)$ 很小时，函数增量 $\Delta f = f(\mathbf{x}\_0 + \Delta \mathbf{x}) - f(\mathbf{x}\_0)$ 可近似为：

$$
\Delta f \approx \sum_{i=1}^{n} \frac{\partial f}{\partial x_i}(\mathbf{x}_0) \Delta x_i
$$

这一线性近似称为**全微分**，记为：

$$
df = \sum_{i=1}^{n} \frac{\partial f}{\partial x_i}(\mathbf{x}_0) \, dx_i
$$

#### **线性近似与几何含义**

全微分提供了函数的线性近似：

$$
f(\mathbf{x}_0 + \Delta \mathbf{x}) \approx f(\mathbf{x}_0) + \sum_{i=1}^{n} \frac{\partial f}{\partial x_i}(\mathbf{x}_0) \Delta x_i
$$

几何上，这对应于函数图形在 $\mathbf{x}_0$ 处的**切超平面**，类似于一元函数的切线。

### 2.2 方向导数与梯度

#### **方向导数**

多元函数不仅沿坐标轴变化，我们还关心沿任意方向的变化率。设 $\mathbf{u} = (u_1, \dots, u_n)$ 为单位向量（ $\|\mathbf{u}\| = 1$ ），方向导数定义为：

$$
\frac{\partial f}{\partial \mathbf{u}}(\mathbf{x}_0) = \lim_{h \to 0} \frac{f(\mathbf{x}_0 + h \mathbf{u}) - f(\mathbf{x}_0)}{h}
$$

它表示函数沿 $\mathbf{u}$ 方向的变化率。

**现在我们关系函数沿哪个方向的变化最大率最大，即求沿哪个方向的方向导数最大。**

$$
\underset{\|\mathbf{u}\|=1}{\max}\;D_{\mathbf{u}}f(\mathbf{x}_0).
$$

$$
\begin{aligned}
D_{\mathbf{u}}f(\mathbf{x}_0)
&:= \lim_{h\to 0}\frac{f(\mathbf{x}_0 + h\mathbf{u}) - f(\mathbf{x}_0)}{h},
\quad \|\mathbf{u}\|=1 \\
&= \sum_{i=1}^{n} \frac{\partial f}{\partial x_i}(\mathbf{x}_0)\,u_i \\
&= \nabla f(\mathbf{x}_0)\cdot \mathbf{u} \\
&= \|\nabla f(\mathbf{x}_0)\|\,\|\mathbf{u}\|\,\cos\theta
= \|\nabla f(\mathbf{x}_0)\|\cos\theta,
\end{aligned}
$$

其中 $\theta$ 是 $\nabla f(\mathbf{x}_0)$ 与 $\mathbf{u}$ 之间的夹角。

其中 $x_0 = (x_{01}, x_{02}, \dots, x_{0n})$ 

发现当且仅当 $\vec{u}$ 和 $\nabla f(\vec x_0)$ 同方向时，方向导数达到最大值。

故我们将 $\nabla f(\vec x_0)$ 称为梯度，记为

 $$\nabla f(\vec x_0) = \left(\frac{\partial f}{\partial x_1}(\vec x_0),\dots,\frac{\partial f}{\partial x_n}(\vec x_0)\right)$$ 

**全微分的梯度表达**
对于 $f:\mathbb{R}^n\to\mathbb{R}$ ，若在 $\mathbf{x}_0$ 可微，则

$$
df(\mathbf{x}_0)
= \sum_{i=1}^n \frac{\partial f}{\partial x_i}(\mathbf{x}_0)\,dx_i
= \nabla f(\mathbf{x}_0)\cdot d\mathbf{x}
$$

### 2.3 多元函数的线性近似及切超平面

从一元函数中我们们得到经验，通过线性近似表达局部行为然后延拓到全域可以得到切超平面方程。

 $$df(\mathbf{x}_0) = \sum_{i=1}^{n} \frac{\partial f}{\partial x_i}(\mathbf{x}_0) \, dx_i = \nabla f(\mathbf{x}_0)\cdot d\mathbf{x}$$ 

 $$\Delta f(\mathbf{x}) \approx \sum_{i=1}^{n} \frac{\partial f}{\partial x_i}(\mathbf{x}_0) \Delta x_i$$ 

 $$f(\vec{x})-f(\vec{x}_0) \approx \sum_{i=1}^{n} \frac{\partial f(\vec{x}_0)}{\partial x_i} (x_i-x_{0i})$$ 

 $$f(\vec{x}) \approx f(\vec{x}_0) + \sum_{i=1}^{n} \frac{\partial f(\vec{x}_0)}{\partial x_i} (x_i-x_{0i})$$ 

故将方程推广到全域即为切超平面方程：

 $$f(\vec{x}) = f(\vec{x}_0) + \sum_{i=1}^{n} \frac{\partial f(\vec{x}_0)}{\partial x_i} (x_i-x_{0i})$$ 

 $$f(\vec{x}) = f(\vec{x}_0) + \nabla f(\vec{x}_0)\cdot (\vec{x}-\vec{x}_0)$$ 

我们得到了线性近似和切超平面方程，但是有的时候我们需要更加精确的近似计算结果，从一元函数得到灵感，我们也可以使用多项式的方式去近似，即多元函数的泰勒展开。

我们显然需要定义出高阶导数,多元函数中应该叫高阶全微分

### 2.4 多元函数的高阶全微分和泰勒展开

#### **高阶全微分**

尝试定义二阶全微分

$$
df(\mathbf{x}_0) = \sum_{i=1}^{n} \frac{\partial f}{\partial x_i}(\mathbf{x}_0) \, dx_i
$$

$$
d(df) = d\left(\sum_{i=1}^{n} \frac{\partial f}{\partial x_i}(\mathbf{x}_0) \, dx_i\right) = \sum_{i=1}^{n} d\left( \frac{\partial f}{\partial x_i}(\mathbf{x}_0) \, dx_i \right)
$$

对于任意项:

 $$d(\frac{\partial f}{\partial x_i}dx_i) = \sum_{j=1}^{n} \frac{\partial^2 f}{\partial x_i \partial x_j}dx_idx_j$$ 

故:

$$
d^2f := d(df) = \sum_{i=1}^{n} \sum_{j=1}^{n} \frac{\partial^2 f}{\partial x_i \partial x_j}dx_idx_j
$$

若二阶偏导数连续有: $\frac{\partial^2 f}{\partial x_i \partial x_j} = \frac{\partial^2 f}{\partial x_j \partial x_i}$ 

介于上述一元函数全微分写成梯度形式(矢量点成),多元函数显然也可以写成类似形式。

**这本质是二重求和的矩阵表达,即二次型:**

$$\begin{aligned}
\sum_{i=1}^n\sum_{j=1}^na_{ij}x_ix_j
\end{aligned}$$

它是由一个求和过程后再求和,单一的求和问题可以转化为两个矩阵的乘积,在对矩阵求和,即转化成三个矩阵乘积.

$$
\begin{aligned}
\sum_{i=1}^n\sum_{j=1}^n a_{ij} x_i x_j 
&= \sum_{i=1}^n \left( x_i (a_{i1} x_1 + a_{i2} x_2 + \cdots + a_{in} x_n) \right) \\
&= \sum_{i=1}^n \left( x_i \begin{pmatrix} a_{i1} & a_{i2} & \cdots & a_{in} \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{pmatrix} \right) \\
&= \begin{pmatrix} x_1 & x_2 & \cdots & x_n \end{pmatrix} 
\begin{pmatrix}
a_{11} & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & \cdots & a_{nn}
\end{pmatrix}
\begin{pmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{pmatrix} \\
&= \mathbf{x}^T A \mathbf{x}
\end{aligned}
$$


因此二阶全微分的定义为:

$$
d^2f(\mathbf{x}_0) = (d\mathbf{x})^T H_f(\mathbf{x}_0) d\mathbf{x}
$$

其中 $H_f(\mathbf{x}_0)$ 为 $f$ 的二次型，被定义为Hessian矩阵：


$$
H_f(\mathbf{x}_0) = \left[\frac{\partial^2 f}{\partial x_i \partial x_j}(\mathbf{x}_0)\right]_{i,j=1}^n
$$
$$
H_f(\mathbf{x}_0) =
\begin{pmatrix}
\frac{\partial^2 f}{\partial x_1^2} & \frac{\partial^2 f}{\partial x_1 \partial x_2} & \cdots & \frac{\partial^2 f}{\partial x_1 \partial x_n} \\
\frac{\partial^2 f}{\partial x_2 \partial x_1} & \frac{\partial^2 f}{\partial x_2^2} & \cdots & \frac{\partial^2 f}{\partial x_2 \partial x_n} \\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial^2 f}{\partial x_n \partial x_1} & \frac{\partial^2 f}{\partial x_n \partial x_2} & \cdots & \frac{\partial^2 f}{\partial x_n^2}
\end{pmatrix}
$$
符号上，有时记作 $H$ 或 $\nabla^2f$ 
**因此，二阶导数可以描述为二次型，沿用线性代数的结论我们可以判定多元函数极值**
多元函数的极值问题->二阶导数的正负->特征值或Sylvester判据


二次型的符号可以由下列方法判定
1. 特征值法
2. Sylvester判据

##### **特征值法**
Hessian矩阵 \( H_f(\mathbf{x}_0) \) 是一个对称矩阵，根据线性代数的性质，它可以被正交对角化。也就是说，存在一个正交矩阵 \( P \)（满足 \( P^T P = I \)），使得：
\[ (d\mathbf{x})^T H_f(\mathbf{x}_0) d\mathbf{x} = (d\mathbf{x})^T (P D P^T) d\mathbf{x} = (P^T d\mathbf{x})^T D (P^T d\mathbf{x}) = \mathbf{w}^T D \mathbf{w} \]

由于 \( D \) 是对角矩阵，展开后有：

\[ \mathbf{w}^T D \mathbf{w} = \sum_{i=1}^n \lambda_i w_i^2 \]

- **正定**：如果所有特征值 \( \lambda_i > 0 \)，则对于任意非零向量 \( d\mathbf{x} \)，有 \( \sum_{i=1}^n \lambda_i w_i^2 > 0 \)，因此 \( H_f(\mathbf{x}_0) \) 是正定的。此时，函数 \( f \) 在 \( \mathbf{x}_0 \) 处有局部极小值。
- **负定**：如果所有特征值 \( \lambda_i < 0 \)，则 \( \sum_{i=1}^n \lambda_i w_i^2 < 0 \)，\( H_f(\mathbf{x}_0) \) 是负定的，函数 \( f \) 在 \( \mathbf{x}_0 \) 处有局部极大值。
- **不定**：如果特征值中既有正值又有负值，则 \( \sum_{i=1}^n \lambda_i w_i^2 \) 的符号取决于 \( \mathbf{w} \) 的选择。例如，可以选择 \( w_i \neq 0 \) 仅对应正特征值，使和为正；或仅对应负特征值，使和为负。因此，\( H_f(\mathbf{x}_0) \) 是不定的，\( \mathbf{x}_0 \) 是鞍点。
- **半定**：如果特征值中有零，则 \( \sum_{i=1}^n \lambda_i w_i^2 \) 可能为零或非零，具体取决于 \( \mathbf{w} \)。此时需要进一步分析，但通常不足以确定严格的极值。


##### **Sylvester判据**

对于 \( n \times n \) 的对称矩阵 \( H_f(\mathbf{x}_0) \)，其 \( k \) 阶主子式 \( \Delta_k \) 定义为左上角 \( k \times k \) 子矩阵的行列式：

\[ \Delta_k = \det \begin{pmatrix}
h_{11} & h_{12} & \cdots & h_{1k} \\
h_{21} & h_{22} & \cdots & h_{2k} \\
\vdots & \vdots & \ddots & \vdots \\
h_{k1} & h_{k2} & \cdots & h_{kk}
\end{pmatrix}
\]
其中，$ h_{ij} = \frac{\partial^2 f}{\partial x_i \partial x_j}(\mathbf{x}_0) $。

- **正定**：\( H_f(\mathbf{x}_0) \) 是正定的，当且仅当所有主子式 \( \Delta_k > 0 \)（\( k = 1, 2, \dots, n \)）。
- **负定**：\( H_f(\mathbf{x}_0) \) 是负定的，当且仅当主子式的符号交替，即 \( (-1)^k \Delta_k > 0 \)：
  - \( \Delta_1 < 0 \)（当 \( k=1 \) 时）
  - \( \Delta_2 > 0 \)（当 \( k=2 \) 时）
  - \( \Delta_3 < 0 \)（当 \( k=3 \) 时）
  - 依此类推。
- **其他情况**：如果主子式不满足上述条件，则 \( H_f(\mathbf{x}_0) \) 可能是半正定、半负定或不定。

综上多元函数的极值问题转化成 Hessain矩阵的正定性问题,我们可以通过特征值法或Sylvester判据来判断Hessian矩阵的正定性。



#### **多元函数的泰勒展开**

由此我们给出**多元函数的泰勒展开**:

设 $f : \mathbb{R}^n \to \mathbb{R}$ 是在点 $\mathbf{x}_0$ 附近具有足够多阶连续偏导数的函数，记 $d\mathbf{x} = \mathbf{x} - \mathbf{x}_0$ ， 
那么 $f(\mathbf{x})$ 在 $\mathbf{x}_0$ 附近的泰勒展开可以写成：

$$
f(\mathbf{x}_0 + d\mathbf{x}) = f(\mathbf{x}_0) + df(\mathbf{x}_0) + \frac{1}{2!} d^2f(\mathbf{x}_0) + \frac{1}{3!} d^3f(\mathbf{x}_0) + \cdots
$$

特别的,如果只展开到二阶（即忽略三阶及以上小量），那么多元泰勒公式写成全微分形式就是：

$$
f(\mathbf{x}_0 + d\mathbf{x}) = f(\mathbf{x}_0) + df(\mathbf{x}_0) + \frac{1}{2} d^2f(\mathbf{x}_0) + o(\|d\mathbf{x}\|^2)
$$
即：
$$
f(\mathbf{x}_0 + d\mathbf{x}) = f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T d\mathbf{x} + \frac{1}{2} (d\mathbf{x})^T H_f(\mathbf{x}_0) d\mathbf{x} + o(\|d\mathbf{x}\|^2)
$$

以上我们完成了多元函数的微分描述任务 $(\mathbb{R}^n \to \mathbb{R})$ ,更进一步的,我们需要考虑向量值函数的微分描述 $(\mathbb{R}^n \to \mathbb{R}^m)$ 

## 3 向量值函数


向量值函数（或向量函数）是将一个标量或向量输入映射到向量输出的函数。具体定义如下：

### 3.1 定义
设 $\mathbf{x} = [x_1, x_2, \dots, x_m]^T \in \mathbb{R}^m$ 是一个 $m$ 维向量（或标量当 $m=1$ ），向量值函数 $\mathbf{f}$ 定义为：
$$
\mathbf{f}: \mathbb{R}^m \to \mathbb{R}^n
$$
其中，输出是一个 $n$ 维向量：
$$
\mathbf{f}(\mathbf{x}) = \begin{bmatrix}
f_1(x_1, x_2, \dots, x_m) \\
f_2(x_1, x_2, \dots, x_m) \\
\vdots \\
f_n(x_1, x_2, \dots, x_m)
\end{bmatrix}
$$
这里的每个分量 $f_i: \mathbb{R}^m \to \mathbb{R}$ （ $i = 1, 2, \dots, n$ ）是一个标量函数。

所以研究向量值函数的微分本质就是在研究标量函数的微分(即前面的多元函数章节)。

### 3.2 向量值函数的全微分
$$
\begin{aligned}
d\mathbf{f}(\mathbf{x}_0) 
&= 
\begin{pmatrix}
 df_1(\mathbf{x}_0) \\
 df_2(\mathbf{x}_0) \\
 \vdots \\
 df_n(\mathbf{x}_0)
\end{pmatrix} \\
&= 
\begin{pmatrix}
\sum_{i=1}^{m} \frac{\partial f_1}{\partial x_i}(\mathbf{x}_0) \, dx_i \\
\sum_{i=1}^{m} \frac{\partial f_2}{\partial x_i}(\mathbf{x}_0) \, dx_i \\
\vdots \\
\sum_{i=1}^{m} \frac{\partial f_n}{\partial x_i}(\mathbf{x}_0) \, dx_i
\end{pmatrix} \\
&=
\begin{pmatrix}
\frac{\partial f_1}{\partial x_1}(\mathbf{x}_0) & \frac{\partial f_1}{\partial x_2}(\mathbf{x}_0) & \cdots & \frac{\partial f_1}{\partial x_m}(\mathbf{x}_0) \\
\frac{\partial f_2}{\partial x_1}(\mathbf{x}_0) & \frac{\partial f_2}{\partial x_2}(\mathbf{x}_0) & \cdots & \frac{\partial f_2}{\partial x_m}(\mathbf{x}_0) \\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial f_n}{\partial x_1}(\mathbf{x}_0) & \frac{\partial f_n}{\partial x_2}(\mathbf{x}_0) & \cdots & \frac{\partial f_n}{\partial x_m}(\mathbf{x}_0)
\end{pmatrix}
\begin{pmatrix}
dx_1 \\ dx_2 \\ \vdots \\ dx_m
\end{pmatrix} \\
&= J_{\mathbf{f}}(\mathbf{x}_0) \, d\mathbf{x}
\end{aligned}
$$

其中 $J_{\mathbf{f}}(\mathbf{x}_0)$ 为函数 $\mathbf{f}$ 在点 $\mathbf{x}_0$ 处的雅可比矩阵（Jacobian matrix），定义为：

$$
J_{\mathbf{f}}(\mathbf{x}) = \left[ \frac{\partial f_i}{\partial x_j}(\mathbf{x}) \right]_{n \times m}
$$

当 $n = 1$ 时,Jacobian 矩阵退化成
$$
J_{\mathbf{f}}(\mathbf{x}) = \left[ \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \dots, \frac{\partial f}{\partial x_m} \right]
$$

这正是梯度 $\nabla f$ 的转置 $(\nabla f)^T$ 。不过，梯度通常定义为列向量，所以 $J_{\mathbf{f}} = (\nabla f)^T$ 。

**因此:Jacobian矩阵是梯度的向量值形式，即每个分量的梯度构成的矩阵。**
**Jacobian 矩阵是向量值函数的一阶导数矩阵。**
**相对的梯度是Jacobian的标量情形**。

特别的,注意到:

- **Hessian 和 Jacobian**：Hessian 矩阵可以看作是梯度 $\nabla f$ 的 Jacobian 矩阵。计算 $\nabla f$ （一个 $m \times 1$ 向量）的 Jacobian：

$$
J_{\nabla f} = \begin{bmatrix}
\frac{\partial}{\partial x_1} \left( \frac{\partial f}{\partial x_1} \right) & \cdots & \frac{\partial}{\partial x_m} \left( \frac{\partial f}{\partial x_1} \right) \\
\vdots & \ddots & \vdots \\
\frac{\partial}{\partial x_1} \left( \frac{\partial f}{\partial x_m} \right) & \cdots & \frac{\partial}{\partial x_m} \left( \frac{\partial f}{\partial x_m} \right)
\end{bmatrix} = H_f
$$



**Hessian是梯度的梯度(二阶变化量)，梯度是矢量，因此对梯度(矢量)求导(即取Jacobian)即得Hessian矩阵。**

**因此， $H_f = J_{\nabla f}$ ，Hessian 是梯度的一阶导数矩阵。**
$H_f = J_{\nabla f}$ 的数学本质在于，Hessian 矩阵是梯度 $\nabla f$ 的 Jacobian 矩阵，**体现了二阶导数对一阶导数的依赖关系**。它不仅提供了函数的二阶变化信息，还在几何、优化和物理学中具有重要意义，反映了函数的局部性质和行为。

### 3.3 向量值函数的线性近似

通俗地， $J_{\mathbf{f}}$ 在每一点给出了 $\mathbf{f}$ 的线性近似。例如，当 $\mathbf{f}$ 在某点 $p$ 可微时， $J_{\mathbf{f}}(p)$ 就是 $\mathbf{f}$ 在该点的导数，即在该点的最佳线性逼近。换言之，当 $\mathbf{x}$ 足够接近 $p$ 时，有
$$
\mathbf{f}(\mathbf{x}) \approx \mathbf{f}(p) + J_{\mathbf{f}}(p)\cdot (\mathbf{x}-p).
$$

### 3.4 向量值函数的泰勒展开



为了在向量值函数中引入高阶近似，我们同样对标量情形的泰勒展开进行推广。设  
\[
\mathbf{f}:\mathbb{R}^m\to\mathbb{R}^n,\quad
\mathbf{x}_0\in\mathbb{R}^m,\quad
\mathbf{h} = \mathbf{x}-\mathbf{x}_0
\]  
当 \(\|\mathbf{h}\|\) 足够小时，\(\mathbf{f}(\mathbf{x}_0+\mathbf{h})\) 可展开为：

$$\boxed{\mathbf{f}(\mathbf{x}_0+\mathbf{h})=\mathbf{f}(\mathbf{x}_0)+\underbrace{J_\mathbf{f}(\mathbf{x}_0)\mathbf{h}}_\text{一阶线性项}+\underbrace{\frac{1}{2}
\begin{pmatrix}
\mathbf{h}^TH_{f_1}(\mathbf{x}_0)\mathbf{h} \\
\mathbf{h}^TH_{f_2}(\mathbf{x}_0)\mathbf{h} \\
\vdots \\
\mathbf{h}^TH_{f_n}(\mathbf{x}_0)\mathbf{h}
\end{pmatrix}}_\text{二阶二次型项}+o(||\mathbf{h}||^2)}$$

- **常数项** \(\mathbf{f}(\mathbf{x}_0)\)：函数在展开点的原始值。  
- **一阶线性项** \(J_{\mathbf{f}}(\mathbf{x}_0)\,\mathbf{h}\)：由雅可比矩阵给出，对应切平面。  
- **二阶二次型项**：每个分量 \(f_i\) 的二阶导数构成 Hessian 矩阵 \(H_{f_i}\)，并通过 \(\mathbf{h}^T H_{f_i}\mathbf{h}\) 给出二阶校正。将所有分量组合，即得到上述向量形式。  
- **余项** \(o(\|\mathbf{h}\|^2)\)：高于二阶的小量。

##### 张量形式

我们也可用三阶张量 \(\mathcal{H}\) 一次性描述所有分量的二阶导数：令

\[
\mathcal{H}\in\mathbb{R}^{n\times m\times m},\quad
\mathcal{H}_{i,j,k} = \frac{\partial^2 f_i}{\partial x_j\partial x_k}(\mathbf{x}_0)
\]

则二阶项可写作：

\[
\bigl(\mathcal{H}[\mathbf{h},\mathbf{h}]\bigr)_i
= \sum_{j,k=1}^m \mathcal{H}_{i,j,k}\,h_j\,h_k
\]

整体展开为：

$$\mathbf{f}(\mathbf{x}_0+\mathbf{h})=\mathbf{f}(\mathbf{x}_0)+J_\mathbf{f}(\mathbf{x}_0)\mathbf{h}+\frac{1}{2}\mathcal{H}[\mathbf{h},\mathbf{h}]+o(\|\mathbf{h}\|^2)$$

这种张量写法在多维高阶分析和自动微分中十分常见。


综上所述:


$$\begin{aligned}
 & f{:}R\to R,df=f^{^{\prime}}(x)dx,d^{2}f=f^{^{\prime\prime}}(x)dx^{2} \\
 & f{:}R^{n}\to R,df=\nabla f(x_{0})\cdot dx,d^{2}f=dx^{T}H_{f}(x_{0})dx \\
 & \left.f{:}R^{n}\to R^{m},df=J_{f}(x_{0})dx,d^{2}f=\left(
\begin{array}
{c}dx^{T}H_{f_{1}}(x_{0})dx \\
dx^{T}H_{f_{2}}(x_{0})dx \\
\vdots \\
dx^{T}H_{f_{m}}(x_{0})dx
\end{array}\right.\right)
\end{aligned}$$


## 4 线性变换与微分

### 4.1 线性变换
#### **定义**
- **加法封闭性**(可加性 additivity)： \( \vec{u}, \vec{v} \in V \)，
  \[
  T(\vec{u} + \vec{v}) = T(\vec{u}) + T(\vec{v})
  \]
- **数乘封闭性**(齐次性 Homogeneity)：对于任意标量 \( c \) 和向量 \( \vec{u} \in V \)，
  \[
  T(c \vec{u}) = c T(\vec{u})
  \]

结合上述性质，线性变换可以写为：
\[
T(c_1 \vec{u} + c_2 \vec{v}) = c_1 T(\vec{u}) + c_2 T(\vec{v})
\]

在有限维向量空间（如 \( \mathbb{R}^n \to \mathbb{R}^m \)）中，线性变换可以用矩阵表示。

#### 矩阵表示
假设 \( V = \mathbb{R}^n \)，\( W = \mathbb{R}^m \)，线性变换 \( T: \mathbb{R}^n \to \mathbb{R}^m \) 可以表示为一个 \( m \times n \) 矩阵 \( A \)。对于任意向量 \( \vec{x} \in \mathbb{R}^n \)，变换结果为：
\[
T(\vec{x}) = A \vec{x}
\]
其中，\( A \) 的第 \( j \) 列是基向量 \( \vec{e}_j \) 经过 \( T \) 变换后的结果。例如，在 \( \mathbb{R}^2 \to \mathbb{R}^2 \) 中，矩阵
\[
A = \begin{bmatrix} a & b \\ c & d \end{bmatrix}
\]

表示：
\[
T\left( \begin{bmatrix} x \\ y \end{bmatrix} \right) = \begin{bmatrix} a & b \\ c & d \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix} = \begin{bmatrix} ax + by \\ cx + dy \end{bmatrix}
\]
**注意:A矩阵需要独立，即不和原空间耦合,不能依赖于输入向量$\vec{x}$**
### 4.2 线性变换与微分

微分与线性变换的联系主要体现在：微分是函数在局部的最佳线性近似。对于多元函数，微分表现为一个线性变换，其矩阵表示正是雅可比矩阵。这种联系在二重积分换元中尤为重要，因为雅可比矩阵描述了坐标变换的局部线性化。

- **一元函数**：对于函数 \( f: \mathbb{R} \to \mathbb{R} \)，在点 \( x_0 \) 处的微分是导数 \( f'(x_0) \)，表示函数在 \( x_0 \) 附近的线性近似：
  \[
  f(x_0 + \Delta x) \approx f(x_0) + f'(x_0) \Delta x
  \]
  这里的 \( f'(x_0) \Delta x \) 是一个线性函数（标量乘法）。

- **多元函数**：对于函数 \( \vec{f}: \mathbb{R}^n \to \mathbb{R}^m \)，
  \[
  \vec{f}(\vec{x}) = (f_1(\vec{x}), \dots, f_m(\vec{x}))
  \]
  在点 \( \vec{x}_0 \) 处的微分是一个线性变换 \( d\vec{f}_{\vec{x}_0}: \mathbb{R}^n \to \mathbb{R}^m \)，满足：
  \[
  \vec{f}(\vec{x}_0 + \Delta \vec{x}) \approx \vec{f}(\vec{x}_0) + d\vec{f}_{\vec{x}_0}(\Delta \vec{x})
  \]
  其中，\( d\vec{f}_{\vec{x}_0} \) 是线性变换，其矩阵表示为雅可比矩阵：
  \[
  J = \begin{bmatrix}
  \frac{\partial f_1}{\partial x_1} & \cdots & \frac{\partial f_1}{\partial x_n} \\
  \vdots & \ddots & \vdots \\
  \frac{\partial f_m}{\partial x_1} & \cdots & \frac{\partial f_m}{\partial x_n}
  \end{bmatrix} \bigg|_{\vec{x}_0}
  \]
  因此：
  \[
  d\vec{f}_{\vec{x}_0}(\Delta \vec{x}) = J_f(\vec{x}_0) \cdot \Delta \vec{x}
  \]

**因此微分是局部的线性变换，Jacobian矩阵描绘了线性变换的特征**

特别的二重积分换元中，面积因子的变换是一种线性变换:

在二重积分换元中，变换为：
\[
x = x(u, v), \quad y = y(u, v)
\]
微分：变换的微分是一个线性变换，雅可比矩阵为：
\[
J = \begin{bmatrix}
\frac{\partial x}{\partial u} & \frac{\partial x}{\partial v} \\
\frac{\partial y}{\partial u} & \frac{\partial y}{\partial v}
\end{bmatrix}
\]
对于微小位移 \( (\Delta u, \Delta v) \)，对应的 \( (xy) \)-平面变化为：
\[
\begin{bmatrix}
\Delta x \\
\Delta y
\end{bmatrix} \approx J \begin{bmatrix}
\Delta u \\
\Delta v
\end{bmatrix}
\]
雅可比矩阵 \( J \) 是局部线性变换，描述了 \( (uv) \)-平面上的微小矩形如何映射到 \( (xy) \)-平面的平行四边形。

- **雅可比行列式**：行列式 \( \text{det}(J) \) 量化了面积缩放：
  \[
  dxdy = |\text{det}(J)| dudv
  \]
  这是因为线性变换 \( J \) 将单位面积映射后，面积变化由 \( \text{det}(J) \) 决定。